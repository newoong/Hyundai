{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f3eb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ldf is not supported\n",
      "xls is not supported\n",
      "xlsx is not supported\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import collections as co\n",
    "import os\n",
    "from datetime import datetime\n",
    "from asammdf import MDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e6f85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "union=np.array(['DTC1_CM','DTC1_VCU','DTC1_CCM','CF_Fcu_CbvSdCmd','CF_Hmu1_LoFuelWrn','CF_Hmu1_TMUDAQReq','CF_VCU_VehSt','BMM2_num_MinCellTemp','PCB_Temp_Slv'])\n",
    "ser=np.array(['BMM2_num_MinCellTemp','PCB_Temp_Slv'])\n",
    "cat=np.array(['DTC1_CM','DTC1_VCU','DTC1_CCM','CF_Fcu_CbvSdCmd','CF_Hmu1_LoFuelWrn','CF_Hmu1_TMUDAQReq','CF_VCU_VehSt'])\n",
    "\n",
    "np.save('//192.168.0.67/hyundai/temp/union_list.npy',union)\n",
    "np.save('//192.168.0.67/hyundai/temp/ser_list.npy',ser)\n",
    "np.save('//192.168.0.67/hyundai/temp/cat_list.npy',cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08b70e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdf2csv1(mdf_path,save_path):\n",
    "    \n",
    "    print(datetime.now())\n",
    "    \n",
    "    mdf_path=mdf_path.rstrip('/')\n",
    "    var_list=np.load('//192.168.0.67/hyundai/temp/union_list.npy')\n",
    "    ser=np.load('//192.168.0.67/hyundai/temp/ser_list.npy')\n",
    "    cat=np.load('//192.168.0.67/hyundai/temp/cat_list.npy')\n",
    "    mdf_list=list(pathlib.Path(mdf_path).glob('*.dat'))\n",
    "    \n",
    "    with open('//192.168.0.67/hyundai/pickle/sd_final.pkl','rb') as f:\n",
    "        sd=pickle.load(f)\n",
    "        \n",
    "    print('start to make csv !')\n",
    "    total=co.deque([])\n",
    "    zero=[]\n",
    "    \n",
    "    for idx,var in enumerate(var_list,start=1):\n",
    "        print('[{}/{}] {:>32s}'.format(idx,len(var_list),var),end='\\r')\n",
    "        time=np.array([])\n",
    "        sample=np.array([])\n",
    "        \n",
    "        for mdf in mdf_list:\n",
    "            data=MDF(mdf)\n",
    "            start_time=data.start_time\n",
    "            locs=data.whereis(var)\n",
    "            for loc in locs:\n",
    "                meta=data.get(group=loc[0],index=loc[1])\n",
    "                time=np.append(time,np.array(start_time+np.round(meta.timestamps*1000,0)*pd.offsets.Milli()))\n",
    "                sample=np.append(sample,meta.samples)\n",
    "                \n",
    "        if len(sample)==0:\n",
    "            print(var,'is not collected in this car. It will be replaced to 0')\n",
    "            zero.append(var)\n",
    "            continue\n",
    "            \n",
    "        df=pd.DataFrame(sample,columns=[var],index=time)\n",
    "        df.index.name='Timestamps'\n",
    "        df.index=pd.to_datetime(df.index)\n",
    "        df.sort_index(inplace=True)\n",
    "        \n",
    "        try:\n",
    "            df[var]=df[var].map(float)\n",
    "            \n",
    "        except:\n",
    "            try:\n",
    "                df[var]=df[var].replace(sd[var])\n",
    "                df=df.resample('1s').apply(lambda x:x.value_counts().index[0] if x.notnull().any() else np.NaN)\n",
    "            except:\n",
    "                print('String type feature \"{}\" replace failed. It will be replaced to 0'.format(var))\n",
    "                zero.append(var)\n",
    "                continue\n",
    "                \n",
    "        if var in cat:\n",
    "            df=df.resample('1s').agg(lambda x:x.value_counts().index[0] if x.notnull().any() else np.NaN)\n",
    "            \n",
    "        elif var in ser:\n",
    "            df=df.resample('1s').mean()\n",
    "            \n",
    "        df.index=df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        total.append(df)\n",
    "        \n",
    "    merge_df=pd.concat(total,axis=1)\n",
    "    merge_df.sort_index(inplace=True)\n",
    "    merge_df.dropna(how='all',inplace=True)\n",
    "    merge_df[zero]=np.array([0]*len(zero)+[np.NaN]*len(merge_df)*(len(zero)-1)).reshape(len(merge_df),-1)\n",
    "    \n",
    "    print('generate csv done !')\n",
    "    \n",
    "    #if not pathlib.Path(save_path).exists():\n",
    "    #    os.mkdir(save_path)\n",
    "        \n",
    "    #merge_df.to_csv(save_path+'/merge_{}.csv'.format(mdf_path.split('/')[-1]))\n",
    "    #print('save csv done !')\n",
    "    print(datetime.now())\n",
    "    \n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbb0c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 16:48:53.218112\n",
      "start to make csv !\n",
      "generate csv done !       PCB_Temp_Slv\n",
      "2023-03-23 16:50:20.244287\n"
     ]
    }
   ],
   "source": [
    "merge_df1=mdf2csv1('//192.168.0.67/hyundai/MDF_Data/220201_51호차','//192.168.0.67/hyundai/CSV')\n",
    "\n",
    "##1분 27초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8563b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdf2csv2(mdf_path,save_path):\n",
    "    \n",
    "    print(datetime.now())\n",
    "    \n",
    "    mdf_path=mdf_path.rstrip('/')\n",
    "    var_list=np.load('//192.168.0.67/hyundai/temp/union_list.npy')\n",
    "    ser=np.load('//192.168.0.67/hyundai/temp/ser_list.npy')\n",
    "    cat=np.load('//192.168.0.67/hyundai/temp/cat_list.npy')\n",
    "    mdf_list=list(pathlib.Path(mdf_path).glob('*.dat'))\n",
    "    \n",
    "    with open('//192.168.0.67/hyundai/pickle/sd_final.pkl','rb') as f:\n",
    "        sd=pickle.load(f)\n",
    "        \n",
    "    print('start to make csv !')\n",
    "    zero=[]\n",
    "    total_dict={}\n",
    "    \n",
    "    for var in var_list:\n",
    "        total_dict[var]=(co.deque([]),co.deque([]))\n",
    "        #(timestamps,samples)\n",
    "    \n",
    "    for idx,mdf in enumerate(mdf_list,start=1):\n",
    "        print('[{}/{}] file start'.format(idx,len(mdf_list)))\n",
    "        data=MDF(mdf)\n",
    "        start_time=data.start_time\n",
    "        for var in var_list:\n",
    "            locs=data.whereis(var)\n",
    "            for loc in locs:\n",
    "                meta=data.get(group=loc[0],index=loc[1])\n",
    "                total_dict[var][0].extend(start_time+np.round(meta.timestamps*1000,0)*pd.offsets.Milli())\n",
    "                total_dict[var][1].extend(meta.samples)\n",
    "                \n",
    "    total=co.deque([])\n",
    "    for var,item in total_dict.items():\n",
    "        df=pd.DataFrame({var:item[1]},index=item[0])\n",
    "        df.index.name='Timestamps'\n",
    "        df.sort_index(inplace=True)\n",
    "        \n",
    "        if len(df)==0:\n",
    "            zero.append(var)\n",
    "            print(var,'is not collected in this car. It will be replaced to 0')\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            df[var]=df[var].map(float)\n",
    "            \n",
    "        except:\n",
    "            try:\n",
    "                df[var]=df[var].replace(sd[var])\n",
    "                df=df.resample('1s').apply(lambda x:x.value_counts().index[0] if x.notnull().any() else np.NaN)\n",
    "            except:\n",
    "                print('String type feature \"{}\" replace failed. It will be replaced to 0'.format(var))\n",
    "                zero.append(var)\n",
    "                continue\n",
    "            \n",
    "        if var in cat:\n",
    "            df=df.resample('1s').agg(lambda x:x.value_counts().index[0] if x.notnull().any() else np.NaN)\n",
    "            \n",
    "        elif var in ser:\n",
    "            df=df.resample('1s').mean()\n",
    "            \n",
    "        df.index=df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        total.append(df)\n",
    "            \n",
    "    merge_df=pd.concat(total,axis=1)\n",
    "    merge_df.sort_index(inplace=True)\n",
    "    merge_df.dropna(how='all',inplace=True)\n",
    "    merge_df[zero]=np.array([0]*len(zero)+[np.NaN]*len(merge_df)*(len(zero)-1)).reshape(len(merge_df),-1)\n",
    "    \n",
    "    print('generate csv done !')\n",
    "    \n",
    "    #if not pathlib.Path(save_path).exists():\n",
    "    #    os.mkdir(save_path)\n",
    "        \n",
    "    #merge_df.to_csv(save_path+'/merge_{}.csv'.format(mdf_path.split('/')[-1]))\n",
    "    #print('save csv done !')\n",
    "    print(datetime.now())       \n",
    "        \n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec260ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 16:07:43.711226\n",
      "start to make csv !\n",
      "generate csv done !       PCB_Temp_Slv\n",
      "2023-03-23 16:09:10.688503\n"
     ]
    }
   ],
   "source": [
    "merge_df2=mdf2csv2('//192.168.0.67/hyundai/MDF_Data/220201_51호차','//192.168.0.67/hyundai/CSV')\n",
    "\n",
    "##1분 27초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "458965b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 17:07:09.572287\n",
      "start to make csv !\n",
      "[1/7] file start\n",
      "[2/7] file start\n",
      "[3/7] file start\n",
      "[4/7] file start\n",
      "[5/7] file start\n",
      "[6/7] file start\n",
      "[7/7] file start\n",
      "generate csv done !\n",
      "2023-03-23 17:08:37.980303\n"
     ]
    }
   ],
   "source": [
    "merge_df3=mdf2csv2('//192.168.0.67/hyundai/MDF_Data/220201_51호차','//192.168.0.67/hyundai/CSV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d45e9570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamps\n",
       "2022-02-02 03:32:31    1.0\n",
       "2022-02-02 03:32:32    1.0\n",
       "2022-02-02 03:46:57    1.0\n",
       "2022-02-02 07:00:04    2.0\n",
       "2022-02-02 07:00:07    2.0\n",
       "2022-02-02 07:04:24    1.0\n",
       "Name: CF_Fcu_CbvSdCmd, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df1['CF_Fcu_CbvSdCmd'][merge_df1['CF_Fcu_CbvSdCmd']!=merge_df3['CF_Fcu_CbvSdCmd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dff4b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamps\n",
       "2022-02-02 03:32:31    0.0\n",
       "2022-02-02 03:32:32    0.0\n",
       "2022-02-02 03:46:57    0.0\n",
       "2022-02-02 07:00:04    0.0\n",
       "2022-02-02 07:00:07    0.0\n",
       "2022-02-02 07:04:24    0.0\n",
       "Name: CF_Fcu_CbvSdCmd, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df3['CF_Fcu_CbvSdCmd'][merge_df1['CF_Fcu_CbvSdCmd']!=merge_df3['CF_Fcu_CbvSdCmd']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
